{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53e1978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7979e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataloader\n",
    "## Check for positive and negative pairs\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        dir1 = '../data/Videos/RECOLA/group-1/P25'\n",
    "        dir2 = '../data/Videos/RECOLA/group-1/P26'\n",
    "        \n",
    "        vid1 = list(Path(dir1).glob('*.pt'))\n",
    "        vid2 = list(Path(dir2).glob('*.pt'))\n",
    "        \n",
    "        self.pairPos = []\n",
    "        self.pairNeg = []\n",
    "        \n",
    "        for i in vid1:\n",
    "            for j in vid2:\n",
    "                if i.name == j.name:\n",
    "                    self.pairPos.append((str(i), str(j)))\n",
    "                else:\n",
    "                    self.pairNeg.append((str(i), str(j)))\n",
    "\n",
    "        self.vidPairs = self.pairPos + self.pairNeg\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.vidPairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.vidPairs[idx]\n",
    "        fname1, fname2 = pair\n",
    "        \n",
    "        center = transforms.CenterCrop(224)\n",
    "        \n",
    "        arr1 = torch.load(fname1, map_location=torch.device('cpu'))\n",
    "        arr1 = center(arr1)\n",
    "        \n",
    "        arr2 = torch.load(fname2, map_location=torch.device('cpu'))\n",
    "        arr2 = center(arr2)\n",
    "        \n",
    "        if pair in self.pairPos:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        return arr1, arr2, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "25d3a8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('../data/Videos/RECOLA/group-1/P25/8.pt', '../data/Videos/RECOLA/group-1/P26/8.pt'), ('../data/Videos/RECOLA/group-1/P25/4.pt', '../data/Videos/RECOLA/group-1/P26/4.pt'), ('../data/Videos/RECOLA/group-1/P25/1.pt', '../data/Videos/RECOLA/group-1/P26/1.pt'), ('../data/Videos/RECOLA/group-1/P25/7.pt', '../data/Videos/RECOLA/group-1/P26/7.pt'), ('../data/Videos/RECOLA/group-1/P25/5.pt', '../data/Videos/RECOLA/group-1/P26/5.pt'), ('../data/Videos/RECOLA/group-1/P25/9.pt', '../data/Videos/RECOLA/group-1/P26/9.pt'), ('../data/Videos/RECOLA/group-1/P25/10.pt', '../data/Videos/RECOLA/group-1/P26/10.pt'), ('../data/Videos/RECOLA/group-1/P25/3.pt', '../data/Videos/RECOLA/group-1/P26/3.pt'), ('../data/Videos/RECOLA/group-1/P25/2.pt', '../data/Videos/RECOLA/group-1/P26/2.pt'), ('../data/Videos/RECOLA/group-1/P25/6.pt', '../data/Videos/RECOLA/group-1/P26/6.pt')]\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bda9ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement dataloader\n",
    "loader = DataLoader(dataset = dataset,\n",
    "                         batch_size = 4,\n",
    "                         shuffle = True,\n",
    "                         num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0732c665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.0059,  0.1047,  0.4675,  ...,  0.2070,  0.1780,  0.0918],\n",
       "          [ 0.0612,  0.1055,  0.2587,  ...,  0.0476,  0.1953,  0.0511],\n",
       "          [ 0.0956,  0.0597,  0.0654,  ..., -0.0451,  0.1472, -0.1271],\n",
       "          ...,\n",
       "          [-0.0249,  0.0334,  0.2441,  ...,  0.1902, -0.3290, -0.0207],\n",
       "          [ 0.0095,  0.0378,  0.2503,  ...,  0.1832, -0.3068, -0.0439],\n",
       "          [-0.0232,  0.0424,  0.2667,  ...,  0.1918, -0.3030, -0.0131]],\n",
       " \n",
       "         [[-0.0158,  0.1008,  0.4353,  ...,  0.2245,  0.1015,  0.0984],\n",
       "          [ 0.0302,  0.1069,  0.3989,  ...,  0.0641,  0.1908,  0.0315],\n",
       "          [ 0.1200,  0.0826,  0.0654,  ..., -0.0347,  0.2109, -0.0822],\n",
       "          ...,\n",
       "          [-0.0416,  0.0188,  0.2450,  ...,  0.2099, -0.3396, -0.0330],\n",
       "          [ 0.0064,  0.0510,  0.2399,  ...,  0.2111, -0.2824, -0.0496],\n",
       "          [-0.0237,  0.0501,  0.2523,  ...,  0.2035, -0.3073, -0.0236]],\n",
       " \n",
       "         [[-0.0464,  0.0436,  0.4316,  ...,  0.2038,  0.0932,  0.1581],\n",
       "          [-0.0352,  0.1016,  0.3556,  ...,  0.1892,  0.0472,  0.1017],\n",
       "          [ 0.0174, -0.0243,  0.2840,  ...,  0.0973,  0.1032,  0.0246],\n",
       "          ...,\n",
       "          [-0.0452,  0.0341,  0.2823,  ...,  0.2092, -0.3005, -0.0162],\n",
       "          [-0.0079,  0.0672,  0.3066,  ...,  0.2202, -0.2632, -0.0263],\n",
       "          [-0.0231,  0.0826,  0.3226,  ...,  0.2231, -0.2471,  0.0114]],\n",
       " \n",
       "         [[-0.0247,  0.1243,  0.4257,  ...,  0.2271,  0.0746,  0.1054],\n",
       "          [ 0.0044,  0.0671,  0.4131,  ...,  0.1890,  0.0933,  0.0967],\n",
       "          [ 0.0213, -0.0007,  0.2558,  ...,  0.0607,  0.1358, -0.0523],\n",
       "          ...,\n",
       "          [-0.0194,  0.0604,  0.2741,  ...,  0.2213, -0.3010,  0.0040],\n",
       "          [-0.0034,  0.0633,  0.2948,  ...,  0.2124, -0.2803, -0.0103],\n",
       "          [-0.0261,  0.0652,  0.3116,  ...,  0.2222, -0.2690,  0.0122]]]),\n",
       " tensor([[[-8.5922e-02,  2.1063e-01,  1.0675e-02,  ..., -1.1857e-01,\n",
       "            3.7663e-02,  8.1386e-02],\n",
       "          [-2.0752e-01,  2.2060e-01,  2.9428e-02,  ..., -5.9569e-02,\n",
       "           -2.0960e-01, -3.7598e-02],\n",
       "          [-7.2659e-02,  8.5918e-02,  5.7984e-02,  ...,  9.5563e-02,\n",
       "           -3.5308e-01, -9.0832e-02],\n",
       "          ...,\n",
       "          [ 1.4850e-01, -5.0571e-02, -1.6750e-01,  ..., -5.6892e-02,\n",
       "           -2.2627e-01, -3.3594e-01],\n",
       "          [-1.6392e-02,  4.0268e-02, -1.7039e-01,  ..., -6.7244e-02,\n",
       "           -1.9741e-01, -3.2680e-01],\n",
       "          [-9.6474e-03,  4.3996e-02, -1.8531e-01,  ...,  5.5898e-02,\n",
       "           -3.3826e-01, -1.9347e-01]],\n",
       " \n",
       "         [[-3.1191e-01,  3.5721e-01, -1.6876e-01,  ..., -3.2439e-02,\n",
       "           -2.9223e-01, -4.2663e-02],\n",
       "          [-7.5294e-02,  6.9274e-02, -2.0296e-02,  ...,  5.4168e-02,\n",
       "           -4.3425e-01, -1.7523e-01],\n",
       "          [ 2.6471e-02,  5.0812e-02,  2.7162e-02,  ...,  1.0969e-01,\n",
       "           -4.6411e-01, -1.9229e-01],\n",
       "          ...,\n",
       "          [ 2.7462e-02, -4.7159e-02, -4.2101e-02,  ..., -5.6149e-02,\n",
       "           -2.5134e-01, -2.4176e-01],\n",
       "          [-6.5828e-02,  1.2674e-01, -8.6152e-02,  ...,  2.4067e-02,\n",
       "           -1.3911e-01, -3.2742e-01],\n",
       "          [-1.6114e-03, -5.0179e-02, -1.0696e-01,  ...,  9.8309e-02,\n",
       "           -3.8863e-01, -2.7514e-01]],\n",
       " \n",
       "         [[-1.1014e-01,  1.3963e-01, -1.3005e-02,  ..., -2.9255e-02,\n",
       "           -4.5461e-02,  6.8158e-02],\n",
       "          [-7.8931e-02,  1.0305e-01, -1.6777e-02,  ..., -4.4886e-02,\n",
       "           -1.1388e-01,  6.4221e-02],\n",
       "          [-1.3374e-01,  1.5633e-01,  6.6647e-02,  ...,  5.7633e-02,\n",
       "           -3.3960e-01, -4.2362e-02],\n",
       "          ...,\n",
       "          [ 3.6850e-02, -4.2240e-02, -2.2091e-02,  ..., -6.1946e-02,\n",
       "           -2.1781e-01, -2.3016e-01],\n",
       "          [ 9.9113e-02,  8.9512e-02, -2.7167e-01,  ...,  2.9653e-02,\n",
       "           -2.5556e-01, -3.4465e-01],\n",
       "          [ 8.8456e-02, -3.1780e-03, -2.5432e-01,  ..., -9.6623e-03,\n",
       "           -3.9397e-01, -3.2094e-01]],\n",
       " \n",
       "         [[-2.1881e-01,  2.2593e-01, -4.7724e-02,  ..., -3.9369e-02,\n",
       "           -2.5100e-01, -1.0515e-04],\n",
       "          [-5.4566e-02,  7.5654e-02,  9.3471e-02,  ...,  9.1546e-02,\n",
       "           -3.1824e-01, -6.1916e-02],\n",
       "          [-7.6752e-03,  6.6078e-02,  1.1325e-01,  ...,  1.2265e-01,\n",
       "           -4.4204e-01, -1.2314e-01],\n",
       "          ...,\n",
       "          [ 5.3790e-02, -1.2087e-01, -1.2299e-01,  ..., -1.6881e-01,\n",
       "           -1.4280e-01, -4.1272e-01],\n",
       "          [ 5.4445e-02,  4.6740e-02, -2.8340e-01,  ..., -8.1911e-02,\n",
       "           -3.4397e-01, -2.2195e-01],\n",
       "          [ 3.3668e-02, -9.5688e-02, -1.7245e-01,  ..., -4.9952e-02,\n",
       "           -3.3115e-01, -3.3798e-01]]]),\n",
       " tensor([0, 1, 0, 0])]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print data items\n",
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a61c5ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtaidistance import dtw_ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74a4a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        # Implement Siamese network with Convolutional Neural Network and Fully Connected Network\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 14 * 14, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "\n",
    "    # Forward pass through the model for a single input\n",
    "    def forward_once(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    # Defines the complete forward pass through the model for a pair of inputs\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0b6c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for learning similarity or dissimilarity between inputs\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        \n",
    "          # Calculate the euclidean distance and calculate the contrastive loss\n",
    "          euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "\n",
    "          loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "\n",
    "          return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5453611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SiameseNetwork()\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fb31b01",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 3, 3, 3], expected input[1, 4, 224, 224] to have 3 channels, but got 4 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Pass in the two images into the network and obtain two outputs\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m output1, output2 \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Pass the outputs of the networks and label into the loss function\u001b[39;00m\n\u001b[1;32m     22\u001b[0m loss_contrastive \u001b[38;5;241m=\u001b[39m criterion(output1, output2, label)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mSiameseNetwork.forward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input1, input2):\n\u001b[0;32m---> 41\u001b[0m     output1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_once(input2)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output1, output2\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mSiameseNetwork.forward_once\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_once\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 34\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     36\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 3, 3, 3], expected input[1, 4, 224, 224] to have 3 channels, but got 4 channels instead"
     ]
    }
   ],
   "source": [
    "# Training loop to train the Siamese network using the contrastive loss\n",
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0\n",
    "\n",
    "# Iterate throught the epochs\n",
    "for epoch in range(10):\n",
    "\n",
    "    # Iterate over batches\n",
    "    for i, (img0, img1, label) in enumerate(loader, 0):\n",
    "\n",
    "        # Send the images and labels to CUDA\n",
    "#         img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass in the two images into the network and obtain two outputs\n",
    "        output1, output2 = net(img0, img1)\n",
    "\n",
    "        # Pass the outputs of the networks and label into the loss function\n",
    "        loss_contrastive = criterion(output1, output2, label)\n",
    "\n",
    "        # Calculate the backpropagation\n",
    "        loss_contrastive.backward()\n",
    "\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # Every 10 batches print out the loss\n",
    "        if i % 10 == 0 :\n",
    "            print(f\"Epoch number {epoch}\\n Current loss {loss_contrastive.item()}\\n\")\n",
    "            iteration_number += 10\n",
    "\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "\n",
    "show_plot(counter, loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933fa4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
